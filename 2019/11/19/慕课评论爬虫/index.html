<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  
  
    <meta name="keywords" content="学习随笔">
  
  
    <meta name="description" content="生死看淡 不服就干">
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <title>
    慕课评论爬虫 |
    
    世纪小小孟</title>
  
    <link rel="shortcut icon" href="/pandas.jpg">
  
  <link rel="stylesheet" href="/css/style.css">
  
    <link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">
  
  <script src="/js/pace.min.js"></script>
</head>

<body>
<main class="content">
  <section class="outer">
  

<article id="post-慕课评论爬虫" class="article article-type-post" itemscope itemprop="blogPost" data-scroll-reveal>
  
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      慕课评论爬虫
    </h1>
  
  




      </header>
    

    
      <div class="article-meta">
        <a href="/2019/11/19/%E6%85%95%E8%AF%BE%E8%AF%84%E8%AE%BA%E7%88%AC%E8%99%AB/" class="article-date">
  <time datetime="2019-11-19T08:55:58.488Z" itemprop="datePublished">2019-11-19</time>
</a>
        
      </div>
    

    
      




    

    <div class="article-entry" itemprop="articleBody">
      


      

      
        <p>﻿﻿看文件看到了今年暑假写的爬虫代码，当时要做数据分析才去学的爬虫。本来对爬虫挺好奇的，但是学了一点之后就没什么兴趣了，特别是看scrapy爬虫框架，我看了连两天没有看明白，笨拙的我果断放弃了scrapy。<br>对于那些动态网页，我就直接采用selenium进行网页加载和模拟点击翻页操作，虽然速度慢，但是对我来说可以问题不大。 毕竟咱也不是做爬虫的，用的时候能爬出来数据就好了。  </p>
<a id="more"></a>
<p>今天看到以前写的代码，觉得以后可能会需要用到爬虫爬点数据啥的，所以有必要把代码保留好，毕竟两个月没写过爬虫我都忘了怎么写的了。<br>爬的是慕课上面一门课程的评论：  </p>
<pre><code class="python"><span class="keyword">import</span> time
<span class="keyword">import</span> re
<span class="keyword">import</span> pandas <span class="keyword">as</span> pd
<span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup
<span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver
<span class="keyword">from</span> selenium.webdriver.support.ui <span class="keyword">import</span> WebDriverWait
<span class="keyword">from</span> selenium.webdriver.support <span class="keyword">import</span> expected_conditions <span class="keyword">as</span> EC
<span class="keyword">from</span> selenium.webdriver.common.by <span class="keyword">import</span> By

<span class="function"><span class="keyword">def</span> <span class="title">comment</span><span class="params">(url,n)</span>:</span>
    driver=webdriver.PhantomJS()
    driver.get(url)
    soup=BeautifulSoup(driver.page_source,<span class="string">'lxml'</span>)

    <span class="comment"># 点击‘课程评价’</span>
    evaluation_click=WebDriverWait(driver,<span class="number">10</span>).until(EC.element_to_be_clickable((By.CSS_SELECTOR,<span class="string">'#review-tag-button'</span>)))
    evaluation_click.click()

    <span class="comment"># 等待加载评论</span>
    time.sleep(<span class="number">2</span>)

    soup=BeautifulSoup(driver.page_source,<span class="string">'lxml'</span>)

    <span class="comment"># 抓取课程总评分</span>
    score=soup.select(<span class="string">'div.ux-mooc-comment-course-comment_head_rating-scores &gt; span'</span>)[<span class="number">0</span>].text
    print(<span class="string">'课程总评分：'</span>,score)
    <span class="comment"># 抓取评论人数</span>
    comment_number=re.findall(<span class="string">'\d+'</span>,soup.select(<span class="string">'#review-tag-num'</span>)[<span class="number">0</span>].text)[<span class="number">0</span>]
    print(<span class="string">'评论次数'</span>,comment_number)
    print(<span class="string">'------------------------'</span>)

    comments=[] <span class="comment"># 评论</span>
    points = [] <span class="comment"># 评分</span>
    p_time = [] <span class="comment"># 发表时间</span>
    c_time = [] <span class="comment"># 对应课时</span>
    like_num=[] <span class="comment"># 点赞人数</span>
    stu_id = []

    <span class="comment"># 抓取单独个人的评价内容、评分、评论点赞数、发布时间、对应课时</span>

    <span class="comment"># --------------------------循环开始----------------------------</span>
    <span class="keyword">for</span> n <span class="keyword">in</span> range(<span class="number">1</span>,n+<span class="number">1</span>): 
        <span class="comment"># 抓取学生id</span>
        stu_name=soup.select(<span class="string">'div.ux-mooc-comment-course-comment_comment-list_item_body &gt; div.ux-mooc-comment-course-comment_comment-list_item_body_user-info &gt; a'</span>)
        stu_id.append([re.findall(<span class="string">'\d+'</span>,x.get(<span class="string">'href'</span>))[<span class="number">1</span>] <span class="keyword">for</span> x <span class="keyword">in</span> stu_name])

        <span class="comment"># 爬取评论内容</span>
        comment=soup.select(<span class="string">'div.ux-mooc-comment-course-comment_comment-list_item_body &gt; div.ux-mooc-comment-course-comment_comment-list_item_body_content &gt; span'</span>)
        list_=[]
        <span class="keyword">for</span> k <span class="keyword">in</span> comment:
            list_.append(k.text)
        comments.append(list_)

        <span class="comment"># 爬取发表时间</span>
        public_time=soup.select(<span class="string">'div.ux-mooc-comment-course-comment_comment-list_item_body_comment-info &gt; div.ux-mooc-comment-course-comment_comment-list_item_body_comment-info_time'</span>)
        list_=[]
        <span class="keyword">for</span> k <span class="keyword">in</span> public_time:
            list_.append(k.text)
        p_time.append(list_)
        <span class="comment"># 爬取评论对应开课次数</span>
        class_time=soup.select(<span class="string">'div.ux-mooc-comment-course-comment_comment-list_item_body_comment-info &gt; div.ux-mooc-comment-course-comment_comment-list_item_body_comment-info_term-sign'</span>)
        list_=[]
        <span class="keyword">for</span> k <span class="keyword">in</span> class_time:
            list_.append(k.text)
        c_time.append(list_)
        <span class="comment"># 爬取点赞次数</span>
        like_number=soup.select(<span class="string">'div.ux-mooc-comment-course-comment_comment-list_item_body_comment-info &gt; div.ux-mooc-comment-course-comment_comment-list_item_body_comment-info_actions &gt; span &gt; span &gt; span:nth-of-type(2)'</span>)
        list_=[]
        <span class="keyword">for</span> k <span class="keyword">in</span> like_number:
            list_.append(k.text)
        like_num.append(list_)
        <span class="comment"># 抓取评分</span>
        goal=soup.select(<span class="string">'div.ux-mooc-comment-course-comment_comment-list_item_body_user-info &gt; span &gt; div &gt; div.star-point'</span>)
        point_list=[]
        <span class="keyword">for</span> i <span class="keyword">in</span> goal:
            point_list.append(len(i.select(<span class="string">'i'</span>)))
        points.append(point_list)


        <span class="comment"># 点击‘下一页’，继续加载评论内容</span>
        next_page=WebDriverWait(driver,<span class="number">10</span>).until(EC.element_to_be_clickable((By.CSS_SELECTOR,<span class="string">'li.ux-pager_btn.ux-pager_btn__next &gt; a'</span>)))
        next_page.click()

        <span class="comment"># 模拟点击与解析页面之间添加sleep，避免爬去重复页面</span>
        time.sleep(<span class="number">2</span>)

        <span class="comment"># 解析当前页面</span>
        soup=BeautifulSoup(driver.page_source,<span class="string">'lxml'</span>)

        print(<span class="string">'已爬取%d页内容！'</span>%n)

    <span class="comment"># -----------------------结束循环-----------------------</span>

    driver.close()

    <span class="comment"># 整理所得结果，使之成为一维列表</span>
    points=[x <span class="keyword">for</span> i <span class="keyword">in</span> points <span class="keyword">for</span> x <span class="keyword">in</span> i]
    like_num=[x <span class="keyword">for</span> i <span class="keyword">in</span> like_num <span class="keyword">for</span> x <span class="keyword">in</span> i]
    c_time=[x <span class="keyword">for</span> i <span class="keyword">in</span> c_time <span class="keyword">for</span> x <span class="keyword">in</span> i]
    p_time=[x <span class="keyword">for</span> i <span class="keyword">in</span> p_time <span class="keyword">for</span> x <span class="keyword">in</span> i]
    comments=[x <span class="keyword">for</span> i <span class="keyword">in</span> comments <span class="keyword">for</span> x <span class="keyword">in</span> i <span class="keyword">if</span> x!=<span class="string">'更多'</span>]
    stu_id=[x <span class="keyword">for</span> i <span class="keyword">in</span> stu_id <span class="keyword">for</span> x <span class="keyword">in</span> i]

    <span class="comment"># 存储结果为DataFrame形式</span>
    <span class="keyword">return</span> pd.DataFrame({
        <span class="string">'学生ID'</span>:stu_id,
        <span class="string">'评论'</span>:comments,
        <span class="string">'评分'</span>:points,
        <span class="string">'发布时间'</span>:p_time,
        <span class="string">'对应课时'</span>:c_time,
        <span class="string">'点赞人数'</span>:like_num
    })

url=<span class="string">'https://www.icourse163.org/course/BIT-1001870001'</span>
n=<span class="number">85</span>
df=comment(url,n)</code></pre>
<p>结果：<br><img src="/images/pachong.png" alt=""></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/11/19/%E6%85%95%E8%AF%BE%E8%AF%84%E8%AE%BA%E7%88%AC%E8%99%AB/" data-id="ck35mn4ug00017424gp837kqm"
         class="article-share-link">Share</a>
      
    </footer>

  </div>

  
    
  <nav class="article-nav">
    
    
      <a href="/2019/11/16/%E5%88%86%E6%B2%BB%E7%AE%97%E6%B3%95-%E6%A3%8B%E7%9B%98%E8%A6%86%E7%9B%96%E9%97%AE%E9%A2%98/" class="article-nav-link">
        <strong class="article-nav-caption">Olde posts</strong>
        <div class="article-nav-title">分治算法-棋盘覆盖问题</div>
      </a>
    
  </nav>


  

  
    
  

</article>



</section>
  <footer class="footer">
  <div class="outer">
    <div class="float-right">
      <ul class="list-inline">
  
    <li><i class="fe fe-smile-alt"></i> <span id="busuanzi_value_site_uv"></span></li>
  
    <li><i class="fe fe-bookmark"></i> <span id="busuanzi_value_page_pv"></span></li>
  
</ul>
    </div>
    <ul class="list-inline">
      <li>&copy; 2019 世纪小小孟</li>
      <li>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a></li>
      <li>Theme  <a href="https://github.com/zhwangart/hexo-theme-ocean" target="_blank" rel="noopener">Ocean</a></li>
    </ul>
  </div>
</footer>

</main>

<aside class="sidebar sidebar-specter">
  
    <button class="navbar-toggle"></button>
<nav class="navbar">
  
    <div class="logo">
      <a href="/"><img src="/images/pandas.jpg" alt="世纪小小孟"></a>
    </div>
  
  <ul class="nav nav-main">
    
      <li class="nav-item">
        <a class="nav-item-link" href="/">Home</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/archives">Archives</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/gallery">Gallery</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/about">About</a>
      </li>
    
    <li class="nav-item">
      <a class="nav-item-link nav-item-search" title="搜索">
        <i class="fe fe-search"></i>
        Search
      </a>
    </li>
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      <div class="totop" id="totop">
  <i class="fe fe-rocket"></i>
</div>
    </li>
    <li class="nav-item">
      
        <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
          <i class="fe fe-feed"></i>
        </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
  </aside>
  <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.justifiedGallery.min.js"></script>
<script src="/js/lazyload.min.js"></script>
<script src="/js/busuanzi-2.3.pure.min.js"></script>

  <script src="/fancybox/jquery.fancybox.min.js"></script>



  <script src="/js/tocbot.min.js"></script>
  <script>
    // Tocbot_v4.7.0  http://tscanlin.github.io/tocbot/
    tocbot.init({
      tocSelector: '.tocbot',
      contentSelector: '.article-entry',
      headingSelector: 'h1, h2, h3, h4, h5, h6',
      hasInnerContainers: true,
      scrollSmooth: true,
      positionFixedSelector: '.tocbot',
      positionFixedClass: 'is-position-fixed',
      fixedSidebarOffset: 'auto',
    });
  </script>


<script src="/js/ocean.js"></script>

</body>
</html>